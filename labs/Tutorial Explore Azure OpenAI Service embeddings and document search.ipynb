{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be8d641-a6c8-4557-8bb1-4d232b744d9a",
   "metadata": {},
   "source": [
    "# Tutorial: Explore Azure OpenAI Service embeddings and document search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592db9be-dfa3-489a-8c87-151fea0b147d",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c1e83a-ece6-4549-997e-0c3735912797",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0c3727-8262-4200-9be0-5e1083d438d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!virtualenv envembeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6200ef-94e9-4498-9266-fae465481191",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source envembeddings/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a837d0fc-0ebe-4030-a235-703b4bee8794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install Python libraries\n",
    "\n",
    "!pip install openai num2words matplotlib plotly scipy scikit-learn pandas tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d4eaf8-3e08-49e4-9f40-5cd241f75d38",
   "metadata": {},
   "source": [
    "### Download the BillSum dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c769e59-0e3a-4acf-bd25-8b857f06026c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl \"https://raw.githubusercontent.com/Azure-Samples/Azure-OpenAI-Docs-Samples/main/Samples/Tutorials/Embeddings/data/bill_sum_data.csv\" --output bill_sum_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af3f94-c9b2-4bd5-8de9-d45c7583e32f",
   "metadata": {},
   "source": [
    "### Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c70eb-7719-4b06-98f1-c3d79ada3bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env AZURE_OPENAI_API_KEY=\"REPLACE_WITH_YOUR_KEY_VALUE_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73922b2e-1014-49fc-b170-4a3d2ef28104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env AZURE_OPENAI_ENDPOINT=\"REPLACE_WITH_YOUR_ENDPOINT_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f6ceb-d9bf-441e-b82d-f58e385b1100",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606f0292-52c2-491e-9e6a-0c4931fe6224",
   "metadata": {},
   "source": [
    "### Import libraries and list models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975042b-6874-4a85-80dd-777779c061f4",
   "metadata": {},
   "source": [
    "In this case, we need to confirm that we have an entry for text-embedding-ada-002. If you find that you're missing this model, you'll need to deploy the model to your resource before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9c542-aec2-47c5-ac17-fefadf26f86c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "from num2words import num2words\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "import tiktoken\n",
    "\n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
    "RESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = API_KEY\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "openai.api_version = \"2022-12-01\"\n",
    "\n",
    "url = openai.api_base + \"/openai/deployments?api-version=2022-12-01\" \n",
    "\n",
    "r = requests.get(url, headers={\"api-key\": API_KEY})\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a0258-9d96-42bb-9350-9ab6f041bcb7",
   "metadata": {},
   "source": [
    "Read our csv file and create a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e4a36-5916-406c-9d6f-247e4fa3236d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(os.path.join(os.getcwd(),'bill_sum_data.csv')) # This assumes that you have placed the bill_sum_data.csv in the same directory you are running Jupyter Notebooks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7364a040-5d15-46df-9cfd-36e9a437d407",
   "metadata": {
    "tags": []
   },
   "source": [
    "Print DataFrame df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6277bf-e0f4-444c-8b16-19489ac90015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035db355-392d-4181-9470-8ddf1f75134d",
   "metadata": {},
   "source": [
    "The initial table has more columns than we need we'll create a new smaller DataFrame called df_bills which will contain only the columns for text, summary, and title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c94ad1-0266-4ce9-8d08-9e16bac60123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_bills = df[['text', 'summary', 'title']]\n",
    "df_bills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74307f4a-7574-447f-aa77-30d191ec6aa5",
   "metadata": {},
   "source": [
    "We'll perform some light data cleaning by removing redundant whitespace and cleaning up the punctuation to prepare the data for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50143d6-6919-4090-bbc4-e74c67f36cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None #https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#evaluation-order-matters\n",
    "\n",
    "# s is input text\n",
    "def normalize_text(s, sep_token = \" \\n \"):\n",
    "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "    # remove all instances of multiple spaces\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\". .\",\".\")\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.strip()\n",
    "    \n",
    "    return s\n",
    "\n",
    "df_bills['text']= df_bills[\"text\"].apply(lambda x : normalize_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893b8b0-35eb-4d2a-95f6-7ff26646f959",
   "metadata": {},
   "source": [
    "Now we need to remove any bills that are too long for the token limit (8192 tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ddd469-890f-4b64-b956-972982600212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "df_bills['n_tokens'] = df_bills[\"text\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "df_bills = df_bills[df_bills.n_tokens<8192]\n",
    "len(df_bills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6374227-bf20-480c-8129-1f645e28f505",
   "metadata": {},
   "source": [
    "We'll once again examine df_bills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c3ab2-2331-4767-bed7-47b754891c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_bills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9b189-ba59-47fe-8cc4-745ee3fa120d",
   "metadata": {},
   "source": [
    "To understand the n_tokens column a little more as well how text ultimately is tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fba88e-cdbb-4c5b-a088-8001aadd56c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_encode = tokenizer.encode(df_bills.text[0]) \n",
    "decode = tokenizer.decode_tokens_bytes(sample_encode)\n",
    "decode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49661fa-7d9c-4689-9e41-0a7824c3387f",
   "metadata": {},
   "source": [
    "If you then check the length of the decode variable, you'll find it matches the first number in the n_tokens column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9fc6f1-22b8-422c-9832-7e14b87bf76a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6da85-25cb-4596-827c-2b8abe74b672",
   "metadata": {},
   "source": [
    "Now that we understand more about how tokenization works we can move on to embedding. It is important to note, that we haven't actually tokenized the documents yet. The n_tokens column is simply a way of making sure none of the data we pass to the model for tokenization and embedding exceeds the input token limit of 8,192. When we pass the documents to the embeddings model, it will break the documents into tokens similar (though not necessarily identical) to the examples above and then convert the tokens to a series of floating point numbers that will be accessible via vector search. These embeddings can be stored locally or in an Azure Database. As a result, each bill will have its own corresponding embedding vector in the new ada_v2 column on the right side of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b64f34-abb2-4656-b932-26b2e02c3480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# engine should be set to the deployment name you chose when you deployed the text-embedding-ada-002 (Version 2) model\n",
    "df_bills['ada_v2'] = df_bills[\"text\"].apply(lambda x : get_embedding(x, engine = 'text-embedding-ada-002')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f10188-1a62-40ea-a5ff-98395a3533a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_bills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f170a5-c361-4a63-b93d-c3260e1819aa",
   "metadata": {},
   "source": [
    "As we run the search code block below, we'll embed the search query \"Can I get information on cable company tax revenue?\" with the same text-embedding-ada-002 (Version 2) model. Next we'll find the closest bill embedding to the newly embedded text from our query ranked by cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d6a9f-53e1-4180-b257-f18056d30195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search through the reviews for a specific product\n",
    "def search_docs(df, user_query, top_n=3, to_print=True):\n",
    "    embedding = get_embedding(\n",
    "        user_query,\n",
    "        engine=\"text-embedding-ada-002\" # engine should be set to the deployment name you chose when you deployed the text-embedding-ada-002 (Version 2) model\n",
    "    )\n",
    "    df[\"similarities\"] = df.ada_v2.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )\n",
    "    if to_print:\n",
    "        display(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "res = search_docs(df_bills, \"Can I get information on cable company tax revenue?\", top_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e6443-b400-496e-a913-af768fa47c68",
   "metadata": {},
   "source": [
    "Finally, we'll show the top result from document search based on user query against the entire knowledge base. This returns the top result of the \"Taxpayer's Right to View Act of 1993\". This document has a cosine similarity score of 0.36 between the query and the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c3e66-99a3-4551-934e-03ba13965cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res[\"summary\"][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f152a3-30d9-4957-a5bf-07c18c003493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res[\"summary\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8125de6b-147f-44e5-aa71-62c4b177a7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
